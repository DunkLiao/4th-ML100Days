{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 專案名稱: 第四屆機器學習百日馬拉松\n",
    "### 功能描述: 第63天作業\n",
    "### 版權所有: Dunk  \n",
    "### 程式撰寫: Dunk  \n",
    "### 撰寫日期：2020/05/22\n",
    "### 改版日期:  \n",
    "### 改版備註:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業\n",
    "* 在精簡深度學習的方式上 : 卷積類神經 (CNN) 採用像素遠近，而遞歸類神經 (RNN) 採用著則是時間遠近\n",
    "* 那麼，既然有著類似的設計精神，兩者是否有可能互換應用呢?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ANS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">雖然兩者在設計精神上有相似之處，某方面來說一定是可以互換應用的，但不同的是CNN有著前饋性而RNN則會遞歸，因此還是要區分不同的適用場景。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN \n",
    "由一個輸入層（像是以數字代表像素來呈現影像）、一個或多個隱藏層和一個輸出層所組成。\n",
    "這些數學運算層有助於電腦一點一滴地定義影像的細節，以求最終能分辨出特定物體或動物或其它目標。不過在辨識時常會出錯，尤其是在訓練初期。\n",
    "\n",
    "- 卷積層：\n",
    "\n",
    "數學裡的卷積是一種循環函數，而在 CNN 裡卷積存在於兩個矩陣（以列和行排列的矩形數字陣列）之間，以形成第三個輸出用的矩陣。\n",
    "\n",
    "CNN 在卷積層裡使用這些卷積來過濾輸入的資料和查找資訊。\n",
    "\n",
    "- Explanation of a Convolution Layer\n",
    "\n",
    "卷積層在 CNN 中負擔多數繁重的運算工作，當成數學過濾器以幫助電腦找出影像邊緣、暗區和亮區、顏色，以及高度、寬度和深度等其它細節。\n",
    "\n",
    "通常會在一個影像上使用多個卷積層過濾器。\n",
    "\n",
    ">- 池化層：池化層（pooling layer）通常夾在卷積層之間，用於減小卷積層創造出的表示內容大小，還有減少對記憶體的需求，以置入更多卷積層。\n",
    ">- 歸一化層：歸一化（normalization）是一種用於提升神經網路效能和穩定性的技術，將所有輸入內容轉換成均值為0、變異數為1的情況，以便更容易管理各層的輸入內容。可以把標準化視為用以規範資料的角色。\n",
    ">- 全連結層：全連結層（fully connected layer）用於將一層裡的各神經元連接到另一層裡的所有神經元。\n",
    "\n",
    "請見 NVIDIA 開發者專區網站的 CNN 頁面，會更深入介紹技術層面。\n",
    "CNN 非常適合用於處理電腦視覺作業，不過要是提供充足資料給 CNN，它也能用於處理影片、語音、音樂和文字。\n",
    "\n",
    "- How a deep neural network sees\n",
    "\n",
    "它們可以在這些隱藏層裡插入一系列已加強辨識影像效率的過濾器（或是神經元）。CNN 採用將資訊從這一層送到下一層的方式，又被稱為「前饋」神經網路。\n",
    "\n",
    "或者 RNN 跟傳統人工神經網路及 CNN 採用幾乎相同的架構，除了它們具有當成回饋迴路的記憶體。就像是人腦會更重視資訊的新近度以預測句子，在談話時尤為如此。\n",
    "\n",
    "這使得 RNN 適合用於預測一系列單字裡接下來的內容，還能將長度不一的資料序列送入 RNN，而 CNN 是使用固定的輸入資料。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN\n",
    "是一個擁有稱為 LSTM 這種活性資料記憶體的神經網路，可以用於一系列資料以猜測接下來會發生的內容。\n",
    "\n",
    "某些層的輸出內容透過 RNN 送回到前一層當成輸入項，如此一來便建立起回饋迴路。\n",
    "\n",
    "我們利用這個經典的例子來說明一個簡單的 RNN：我們想要追蹤餐廳供應主菜的日期，嚴格奉行每週的同一天出同一道菜，假設週一提供漢堡、週二提供玉米餅、週三提供披薩、週四提供壽司、周五提供義大利麵。\n",
    "\n",
    "在使用 RNN 的情況下，要是將輸出項「壽司」送回神經網路以判斷週五的主菜，那麼 RNN 就會知道序列中的下一個主菜是義大利麵（它已經知道主菜的順序，這時又剛送出週四的主菜資料，便能得知週五的主菜是什麼）。\n",
    "\n",
    "這裡用句子來當成下一個例子：我跑了十英里，需要喝一杯______。人類會按照過去的經驗想出空格內要填入什麼，而過去可能有使用類似句子來訓練 RNN 的記憶功能，使得 RNN 可以預測接下來的內容，便會在空格處填入「水」這個字。\n",
    "\n",
    "RNN 不單能用於處理自然語言和語音辨識，還能用於語言翻譯、股票預測和演算法交易。\n",
    "\n",
    "神經網路圖靈機（neural Turing machine，NTM）則是能存取外部記憶體的 RNN。\n",
    "\n",
    "最後所謂的雙向 RNN 接受一個輸入向量，並且在兩個 RNN 上訓練它，其中一個在常規 RNN 輸入序列上接受訓練，而另一個則是在反向序列上進行訓練，然後再將兩個 RNN 的輸出內容進行串連或合併。\n",
    "\n",
    "總而言之，CNN 與 RNN 使得 app、網路及機器擁有更強大的視覺和語音能力，要是少了這兩項強大的人工智慧技術，很多機器就會變得一點都不有趣了。\n",
    "\n",
    "像是 Amazon 的 Alexa 讓我們知道怎麼跟廚房裡的 Echo「收音機」聊天，用它奇特的人工智慧技術回答各種新的問題。\n",
    "\n",
    "即將上路的自動駕駛車，會在我們的生活裡扮演主角。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 參考資料\n",
    "[【神經網路】各類神經網路架構剖析（附原始論文地址）](https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/599929/ \"【神經網路】各類神經網路架構剖析（附原始論文地址）\")\n",
    "\n",
    "[CNN 與 RNN 之間的差異？](https://blogs.nvidia.com.tw/2018/09/whats-the-difference-between-a-cnn-and-an-rnn/ \"CNN 與 RNN 之間的差異？\")\n",
    "\n",
    "[從神經元到CNN、RNN、GAN…神經網路看本文絕對夠了](https://www.itread01.com/content/1541515930.html \"從神經元到CNN、RNN、GAN…神經網路看本文絕對夠了\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
