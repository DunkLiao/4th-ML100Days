{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 專案名稱: 第四屆機器學習百日馬拉松\n",
    "### 功能描述: 第3天作業\n",
    "### 版權所有: Dunk  \n",
    "### 程式撰寫: Dunk  \n",
    "### 撰寫日期：2020/02/20\n",
    "### 改版日期:  \n",
    "### 改版備註:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業目標]\n",
    "持續接觸有關機器學習的相關專案與最新技術"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "透過觀察頂尖公司的機器學習文章，來了解各公司是怎麼應用機器學習在實際的專案上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業]\n",
    "今天的作業希望大家能夠看看全球機器學習巨頭們在做的機器學習專案。以 google 為例，下圖是 Google 內部專案使用機器學習的數量，隨著時間進展，現在早已超過 2000 個專案在使用機器學習。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cdn-images-1.medium.com/max/800/1*U_L8qI8RmYS-MOBrYvXhSA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "底下幫同學整理幾間知名企業的 blog 或機器學習網站 (自行搜尋也可)，這些網站都會整理最新的機器學習專案或者是技術文章，請挑選一篇文章閱讀並試著回答\n",
    "1. 專案的目標？ (要解決什麼問題）\n",
    "2. 使用的技術是？ (只需知道名稱即可，例如：使用 CNN 卷積神經網路做影像分類)\n",
    "3. 資料來源？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Google AI blog](https://ai.googleblog.com/)\n",
    "- [Facebook Research blog](https://research.fb.com/blog/)\n",
    "- [Apple machine learning journal](https://machinelearning.apple.com/)\n",
    "- [機器之心](https://www.jiqizhixin.com/)\n",
    "- [雷鋒網](http://www.leiphone.com/category/ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ans:\n",
    "我找的文章連結如下:\n",
    "### https://ai.googleblog.com/2020/02/ml-fairness-gym-tool-for-exploring-long.html\n",
    "***\n",
    "### 1.專案的目標？ (要解決什麼問題）\n",
    "\n",
    "ML-fairness-gym是用於構建簡單模擬的一組組件，這些模擬探索了在社交環境中部署基於機器學習的決策系統的潛在長期影響。隨著機器學習公平性的重要性變得越來越明顯，最近的研究集中在最初在靜態環境中定義的執行公平性措施的潛在長期令人驚訝的行為。主要發現表明，在簡化的動態模擬的特定假設下，長期影響實際上可能抵消預期的目標。因此，更深入地了解這種長期影響是機器學習公平性研究的關鍵方向。ML-fairness-gym實施了一個通用框架，用於在精心構造的模擬場景中研究和探究長期公平效應，在這種模擬場景中，學習代理會隨時間與環境互動。這項工作適合公平機器學習文獻的更大推動，以設計從長遠來看會導致公平結果的決策系統，並了解這些系統可能與旨在一次性實現公平的系統有何不同。\n",
    "\n",
    "許多現有的ML公平性工具包（例如AIF360，fairlearn，fairness-indicators，公平性比較）提供了用於對現有數據集執行此類基於錯誤度量的分析的工具。儘管這種分析可能適用於簡單環境中的系統，但在某些情況下（例如，具有活動數據收集或重要反饋循環的系統），算法在其中運行的上下文對於理解其影響至關重要。在這些情況下，理想情況下，比基於錯誤度量的技術所允許的，在分析環境和時間上下文時，最好對算法決策的公平性進行分析。\n",
    "\n",
    "### 2.使用的技術是？ (只需知道名稱即可，例如：使用 CNN 卷積神經網路做影像分類)\n",
    "\n",
    "ML-fairness-gym使用Open AI的Gym框架模擬順序決策。在此框架中，代理能夠與模擬環境進行交互。在每個步驟中，代理都會選擇一個會影響環境狀態的操作。然後環境則會揭示代理用來通知其後續操作的觀察結果。最後，環境對系統和問題的動態進行建模，觀察結果用作代理的數據，這樣就可以將其編碼為機器學習系統。\n",
    "<img src=\"https://1.bp.blogspot.com/-I9j8PhS9rZQ/XjstEhbRKQI/AAAAAAAAFQg/CjrLHsNc9z0bg0pyA5Bs9UN-djPgOzuYQCEwYBhgL/s400/image2.png\"/>\n",
    "\n",
    "### 3.資料來源？\n",
    "機器學習中用於評估諸如貸款問題之類的情景的影響的標準實踐是將一部分數據保留為“ 測試集 ”，並使用其來計算相關的性能指標。然後通過查看這些績效指標在不同顯著群體之間的差異來評估公平性。但是，眾所周知，在具有反饋的系統中使用這樣的測試集存在兩個主要問題。如果測試集是從現有系統生成的，則它們可能不完整或反映出偏差這些系統固有的。在放貸示例中，測試集可能是不完整的，因為它可能僅包含有關已獲得貸款的申請人是否拖欠或還款的信息。因此，數據集可能不包括未批准其貸款或之前從未獲得貸款的個人。\n",
    "\n",
    "第二個問題是，機器學習系統的輸出所通知的操作可能會產生影響其未來輸入的影響。機器學習系統確定的閾值用於擴展貸款。人們是否拖欠或償還這些貸款，都會影響他們未來的信用評分，然後將其反饋到ML系統中。\n",
    "\n",
    "這些問題突出了評估靜態數據集中公平性的缺點，並激發了在部署動態系統的情況下分析算法公平性的需求。我們創建了ML-fairness-gym框架，以幫助ML練習者將基於仿真的分析引入其ML系統，該方法在許多領域中都非常有效，可用於分析難以進行封閉式分析的動態系統。\n",
    "\n",
    "### 參考網址\n",
    "\n",
    "https://ai.googleblog.com/2020/02/ml-fairness-gym-tool-for-exploring-long.html\n",
    "\n",
    "https://kknews.cc/tech/rnmpl5r.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
